ğŸš– NYC Taxi Trip Duration Prediction - MLOps Project

**Task:** Predict NYC taxi trip duration (regression)  
**Dataset:** [NYC Taxi Trip Duration | Kaggle](https://www.kaggle.com/competitions/nyc-taxi-trip-duration)  
**Team:** Carla & Mariane  
**Course:** MLOps Course - USJ  
**Repository:** https://github.com/carlasleiman/mlops2025_carla_mariane
```
## ğŸ“ Project Structure
mlops2025_carla_mariane/
â”œâ”€â”€ src/mlproject/
â”‚ â”œâ”€â”€ data/ # Data utilities
â”‚ â”œâ”€â”€ preprocess/ # Preprocessing modules (Carla)
â”‚ â”œâ”€â”€ features/ # Feature engineering (Mariane)
â”‚ â”œâ”€â”€ train/ # Training modules (Carla)
â”‚ â”œâ”€â”€ inference/ # Inference modules (Mariane)
â”‚ â”œâ”€â”€ pipelines/ # Pipeline orchestration (Carla)
â”‚ â”œâ”€â”€ utils/ # Utility functions (Mariane)
â”‚ â””â”€â”€ init.py
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ preprocess.py # Data preprocessing (Carla)
â”‚ â”œâ”€â”€ feature_engineering.py # Feature engineering (Mariane)
â”‚ â”œâ”€â”€ train.py # Model training (Carla)
â”‚ â””â”€â”€ batch_inference.py # Batch inference (Mariane)
â”œâ”€â”€ configs/ # Configuration files (Carla)
â”œâ”€â”€ tests/ # Test suite (Both)
â”œâ”€â”€ Dockerfile # Docker setup (Carla)
â”œâ”€â”€ docker-compose.yml # Multi-container (Carla)
â”œâ”€â”€ pyproject.toml # Package config (Carla)
â”œâ”€â”€ uv.lock # Locked dependencies (Carla)
â””â”€â”€ README.md # Documentation (Carla)
```
text

## ğŸš€ Quick Start
### 1. Setup Environment
```bash
git clone https://github.com/carlasleiman/mlops2025_carla_mariane.git
cd mlops2025_carla_mariane
uv sync
2. Run Pipeline
bash
# Full training pipeline
uv run train

# Generate predictions
uv run inference
3. Individual Stages
bash
uv run python scripts/preprocess.py
uv run python scripts/feature_engineering.py
uv run python scripts/train.py
uv run python scripts/batch_inference.py
ğŸ³ Docker Deployment
Build and Run
bash
docker build -t mlops-taxi .
docker-compose run app train
docker-compose run app inference
â˜ï¸ AWS SageMaker Deployment
Training Pipeline (Mariane)
bash
python scripts/run_training_pipeline.py \
  --role-arn <your-arn> \
  --bucket <your-bucket> \
  --prefix mlops-project
Inference Pipeline (Mariane)
bash
python scripts/run_batch_inference_pipeline.py \
  --model-path s3://<path>/models/ \
  --input-data s3://<path>/test.csv
ğŸ“Š Model Selection & Evaluation
Evaluation Metric: Root Mean Squared Error (RMSE)

Justification:

Sensitive to large errors (important for trip duration)

Same units as target (seconds)

Standard for regression tasks

Models Evaluated:

Random Forest Regressor

XGBoost Regressor

Results:

Model	Validation RMSE	Training Time
Random Forest	345.2 seconds	2.1 minutes
XGBoost	321.8 seconds	1.8 minutes
Final Model: XGBoost Regressor

Lower RMSE (321.8s vs 345.2s)

Faster training & inference

Better generalization

ğŸ‘¥ Team Responsibilities
Carla
Preprocessing: Data cleaning, missing values, outliers

Training: Model training, hyperparameter tuning

Docker: Dockerfile, docker-compose setup

CI/Setup: GitHub Actions workflow, project structure

Configuration: OmegaConf config management

Packaging: src/ layout, pyproject.toml

Documentation: README.md

Mariane
Features: Feature engineering, distance calculations

Inference: Batch prediction pipeline

SageMaker: AWS training & inference pipelines

S3 Integration: Cloud storage setup

Testing: Feature and inference tests

ğŸ”§ Key Commands
Testing
bash
uv run pytest tests/ -v
CI Pipeline (GitHub Actions)
Runs on push/pull request

Installs dependencies with uv

Runs test suite

Validates preprocessing

Configuration
Uses OmegaConf (configs/train.yaml)

Centralized settings for training/inference

Easy parameter tuning

âœ… Requirements Met
Mandatory:
Git workflow with feature branches + PRs

uv dependency management

src/ layout Python packaging

Docker & docker-compose

AWS SageMaker pipelines

Complete ML pipeline

CLI: uv run train & uv run inference

Best Practices:
Reproducible environment

Configuration management

Testing suite

Modular structure

Clear team contributions

Course: MLOps - USJ
Status: âœ… Complete & Production-Ready
Last Updated: January 2025
